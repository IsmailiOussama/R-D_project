{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# d4rl outils"
      ],
      "metadata": {
        "id": "DaZuiOe3dTu0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hG3kJVG3c8OS",
        "outputId": "a5282336-9b66-40ef-b5f4-cda91148027e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gymnasium[mujoco]\n",
            "  Downloading gymnasium-1.0.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[mujoco]) (1.26.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[mujoco]) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[mujoco]) (4.12.2)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium[mujoco])\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)\n",
            "Collecting mujoco>=2.1.5 (from gymnasium[mujoco])\n",
            "  Downloading mujoco-3.2.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: imageio>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium[mujoco]) (2.36.1)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.11/dist-packages (from imageio>=2.14.1->gymnasium[mujoco]) (11.1.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from mujoco>=2.1.5->gymnasium[mujoco]) (1.4.0)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.11/dist-packages (from mujoco>=2.1.5->gymnasium[mujoco]) (1.11.0)\n",
            "Collecting glfw (from mujoco>=2.1.5->gymnasium[mujoco])\n",
            "  Downloading glfw-2.8.0-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38.p39.p310.p311.p312.p313-none-manylinux_2_28_x86_64.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: pyopengl in /usr/local/lib/python3.11/dist-packages (from mujoco>=2.1.5->gymnasium[mujoco]) (3.1.7)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from etils[epath]->mujoco>=2.1.5->gymnasium[mujoco]) (2024.10.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.11/dist-packages (from etils[epath]->mujoco>=2.1.5->gymnasium[mujoco]) (6.5.2)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.11/dist-packages (from etils[epath]->mujoco>=2.1.5->gymnasium[mujoco]) (3.21.0)\n",
            "Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Downloading mujoco-3.2.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gymnasium-1.0.0-py3-none-any.whl (958 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m958.1/958.1 kB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading glfw-2.8.0-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38.p39.p310.p311.p312.p313-none-manylinux_2_28_x86_64.whl (243 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.4/243.4 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: glfw, farama-notifications, gymnasium, mujoco\n",
            "Successfully installed farama-notifications-0.0.4 glfw-2.8.0 gymnasium-1.0.0 mujoco-3.2.7\n"
          ]
        }
      ],
      "source": [
        "!pip install gymnasium[mujoco]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch numpy matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-Fwoq1ZdI53",
        "outputId": "4222ca15-ed38-4059-d865-57d2c8ab2a72"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install just-d4rl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5TDjJgodLBF",
        "outputId": "e8463201-364f-47a6-c40b-8ab8c9dcab51"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting just-d4rl\n",
            "  Downloading just_d4rl-0.2407.5-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from just-d4rl) (3.12.1)\n",
            "Requirement already satisfied: tqdm>=4.66.4 in /usr/local/lib/python3.11/dist-packages (from just-d4rl) (4.67.1)\n",
            "Requirement already satisfied: torch>=2 in /usr/local/lib/python3.11/dist-packages (from just-d4rl) (2.5.1+cu121)\n",
            "Requirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.11/dist-packages (from h5py>=3.11.0->just-d4rl) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2->just-d4rl) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2->just-d4rl) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2->just-d4rl) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2->just-d4rl) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2->just-d4rl) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=2->just-d4rl) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=2->just-d4rl) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=2->just-d4rl) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2->just-d4rl) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2->just-d4rl) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=2->just-d4rl) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=2->just-d4rl) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=2->just-d4rl) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=2->just-d4rl) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2->just-d4rl) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=2->just-d4rl) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2->just-d4rl) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2->just-d4rl) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2->just-d4rl) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2->just-d4rl) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2->just-d4rl) (3.0.2)\n",
            "Downloading just_d4rl-0.2407.5-py3-none-any.whl (8.2 kB)\n",
            "Installing collected packages: just-d4rl\n",
            "Successfully installed just-d4rl-0.2407.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install stable_baselines3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_n7HF1NbdN_Y",
        "outputId": "7312d63a-6d2e-460c-f7ab-28f4f8033376"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting stable_baselines3\n",
            "  Downloading stable_baselines3-2.4.1-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: gymnasium<1.1.0,>=0.29.1 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (1.0.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (1.26.4)\n",
            "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (2.5.1+cu121)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (3.1.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.1.0,>=0.29.1->stable_baselines3) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.1.0,>=0.29.1->stable_baselines3) (0.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable_baselines3) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable_baselines3) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable_baselines3) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable_baselines3) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable_baselines3) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable_baselines3) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable_baselines3) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable_baselines3) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable_baselines3) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable_baselines3) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable_baselines3) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable_baselines3) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable_baselines3) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable_baselines3) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable_baselines3) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable_baselines3) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable_baselines3) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13->stable_baselines3) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13->stable_baselines3) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->stable_baselines3) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable_baselines3) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->stable_baselines3) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13->stable_baselines3) (3.0.2)\n",
            "Downloading stable_baselines3-2.4.1-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.0/184.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: stable_baselines3\n",
            "Successfully installed stable_baselines3-2.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XUKKdO-tdQYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Videos"
      ],
      "metadata": {
        "id": "Xysa2yO_DUaq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "import torch\n",
        "import numpy as np\n",
        "import os\n",
        "import imageio\n",
        "from stable_baselines3.common import policies\n",
        "from just_d4rl import d4rl_offline_dataset\n",
        "from stable_baselines3.common.torch_layers import FlattenExtractor, MlpExtractor\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "# Define UnconditionalPolicy\n",
        "class UnconditionalPolicy(policies.ActorCriticPolicy):\n",
        "    def __init__(\n",
        "        self,\n",
        "        observation_space,\n",
        "        action_space,\n",
        "        hidden_size=1024,\n",
        "        depth=2,\n",
        "        learning_rate=1e-3,\n",
        "    ):\n",
        "        net_arch = dict(\n",
        "            pi=[hidden_size] * depth,\n",
        "            vf=[64]\n",
        "        )\n",
        "        super().__init__(\n",
        "            observation_space=observation_space,\n",
        "            action_space=action_space,\n",
        "            lr_schedule=lambda _: learning_rate,\n",
        "            net_arch=net_arch,\n",
        "            activation_fn=nn.ReLU,\n",
        "            features_extractor_class=FlattenExtractor,\n",
        "            optimizer_class=torch.optim.Adam,\n",
        "        )\n",
        "\n",
        "    def _build(self, lr_schedule):\n",
        "        self.features_extractor = self.features_extractor_class(self.observation_space)\n",
        "        self.features_dim = self.features_extractor.features_dim\n",
        "\n",
        "        self.mlp_extractor = MlpExtractor(\n",
        "            self.features_dim,\n",
        "            net_arch=self.net_arch,\n",
        "            activation_fn=self.activation_fn,\n",
        "        )\n",
        "\n",
        "        self.value_net = nn.Linear(self.mlp_extractor.latent_dim_vf, 1)\n",
        "\n",
        "        latent_dim_pi = self.mlp_extractor.latent_dim_pi\n",
        "        self.action_net, self.log_std = self.action_dist.proba_distribution_net(\n",
        "            latent_dim=latent_dim_pi,\n",
        "            log_std_init=self.log_std_init\n",
        "        )\n",
        "\n",
        "\n",
        "# Load the UnconditionalPolicy model\n",
        "def load_model(model_class, model_path, observation_space, action_space):\n",
        "    model = model_class(\n",
        "        observation_space=observation_space,\n",
        "        action_space=action_space,\n",
        "        hidden_size=1024,\n",
        "        depth=2\n",
        "    )\n",
        "    model.load_state_dict(torch.load(model_path, map_location=torch.device('cuda')))\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "\n",
        "# Set the OpenGL backend for headless rendering\n",
        "os.environ[\"MUJOCO_GL\"] = \"egl\"\n",
        "\n",
        "\n",
        "# Function to save frames to video\n",
        "def save_video_from_frames(frames, video_filename):\n",
        "    writer = imageio.get_writer(video_filename, fps=60)\n",
        "    for frame in frames:\n",
        "        writer.append_data(frame)\n",
        "    writer.close()\n",
        "    print(f\"Video saved at: {video_filename}\")\n",
        "\n",
        "\n",
        "# Evaluate the model and save video\n",
        "def evaluate_model_and_save_video(model, env_name, video_filename, state_mean, state_std, num_evaluations=10, desired_return=12000 * 0.001):\n",
        "    env = gym.make(env_name, render_mode=\"rgb_array\")\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    frames = []\n",
        "    total_rewards = []\n",
        "\n",
        "    for ep in range(num_evaluations):\n",
        "        obs, _ = env.reset()\n",
        "        total_reward = 0\n",
        "        done = False\n",
        "        desired_return_ep = desired_return  # Reset desired return for this episode\n",
        "\n",
        "        while not done:\n",
        "            # Normalize state\n",
        "            state = (torch.tensor(obs, dtype=torch.float32).to(device) - state_mean) / state_std\n",
        "            state = state.unsqueeze(0)\n",
        "\n",
        "            # Add desired return to state\n",
        "            desired_return_tensor = torch.tensor([[desired_return_ep]], dtype=torch.float32).to(device)\n",
        "            augmented_state = torch.cat([state, desired_return_tensor], dim=1)\n",
        "\n",
        "            # Predict action\n",
        "            action = model._predict(augmented_state, deterministic=True).detach().cpu().numpy().flatten()\n",
        "            action = np.clip(action, env.action_space.low, env.action_space.high)  # Clip actions\n",
        "\n",
        "            # Step environment\n",
        "            obs, reward, terminated, truncated, _ = env.step(action)\n",
        "            done = terminated or truncated\n",
        "            total_reward += reward\n",
        "\n",
        "            # Update desired return\n",
        "            desired_return_ep -= reward * 0.001\n",
        "            frame = env.render()\n",
        "            frames.append(frame)\n",
        "\n",
        "        print(f\"Sum of Reward for this episode: {total_reward}\")\n",
        "        total_rewards.append(total_reward)\n",
        "\n",
        "    save_video_from_frames(frames, video_filename)\n",
        "    avg_reward = np.mean(total_rewards)\n",
        "    print(f\"Average Reward over {num_evaluations} evaluations: {avg_reward}\")\n",
        "    return avg_reward\n",
        "\n",
        "\n",
        "# Main function\n",
        "def main():\n",
        "    dataset_name = \"halfcheetah-medium-expert-v2\"\n",
        "    model_path = f\"trained_mle_model_{dataset_name}.pth\"\n",
        "    video_filename = f\"./{dataset_name}_evaluation.mp4\"\n",
        "\n",
        "    env_name = dataset_name.split('-')[0].replace('halfcheetah', 'HalfCheetah') + '-v4'\n",
        "    env = gym.make(env_name, render_mode=\"rgb_array\")\n",
        "\n",
        "    action_space = env.action_space\n",
        "    augmented_obs_space = gym.spaces.Box(\n",
        "        low=np.concatenate([env.observation_space.low, [-np.inf]]),\n",
        "        high=np.concatenate([env.observation_space.high, [np.inf]]),\n",
        "        dtype=np.float32\n",
        "    )\n",
        "\n",
        "    # Load the model\n",
        "    model = load_model(UnconditionalPolicy, model_path, augmented_obs_space, action_space)\n",
        "\n",
        "    # Load dataset statistics for normalization\n",
        "    dataset = d4rl_offline_dataset(dataset_name)\n",
        "    states = dataset['observations']\n",
        "    state_mean = torch.tensor(states.mean(axis=0), dtype=torch.float32).to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    state_std = torch.tensor(states.std(axis=0) + 1e-6, dtype=torch.float32).to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # Evaluate the model and save video\n",
        "    avg_reward = evaluate_model_and_save_video(\n",
        "        model,\n",
        "        env_name,\n",
        "        video_filename,\n",
        "        state_mean,\n",
        "        state_std,\n",
        "        num_evaluations=10,\n",
        "        desired_return=12000 * 0.001\n",
        "    )\n",
        "\n",
        "    print(f\"Final Average Reward for {dataset_name}: {avg_reward}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDOn9S9yto1n",
        "outputId": "638049f5-5950-4ef9-fb88-6ce3bc324cab"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gymnasium/envs/registration.py:517: DeprecationWarning: \u001b[33mWARN: The environment HalfCheetah-v4 is out of date. You should consider upgrading to version `v5`.\u001b[0m\n",
            "  logger.deprecation(\n",
            "<ipython-input-18-7fa3f4aa3cb0>:63: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path, map_location=torch.device('cuda')))\n",
            "load datafile: 100%|██████████| 9/9 [00:05<00:00,  1.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded and saved at: /root/.d4rl/datasets/halfcheetah_medium_expert-v2.hdf5\n",
            "Sum of Reward for this episode: 11624.95245774274\n",
            "Sum of Reward for this episode: 11218.757056662911\n",
            "Sum of Reward for this episode: 11279.934292811216\n",
            "Sum of Reward for this episode: 11289.573013770796\n",
            "Sum of Reward for this episode: 11457.571741994941\n",
            "Sum of Reward for this episode: 11162.789090940802\n",
            "Sum of Reward for this episode: 11290.620105226268\n",
            "Sum of Reward for this episode: 11247.596560491667\n",
            "Sum of Reward for this episode: 11258.79190017032\n",
            "Sum of Reward for this episode: 11190.02640530622\n",
            "Video saved at: ./halfcheetah-medium-expert-v2_evaluation.mp4\n",
            "Average Reward over 10 evaluations: 11302.061262511788\n",
            "Final Average Reward for halfcheetah-medium-expert-v2: 11302.061262511788\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "import torch\n",
        "import numpy as np\n",
        "import os\n",
        "import imageio\n",
        "from stable_baselines3.common import policies\n",
        "from just_d4rl import d4rl_offline_dataset\n",
        "from stable_baselines3.common.torch_layers import FlattenExtractor, MlpExtractor\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "# Define UnconditionalPolicy\n",
        "class UnconditionalPolicy(policies.ActorCriticPolicy):\n",
        "    def __init__(\n",
        "        self,\n",
        "        observation_space,\n",
        "        action_space,\n",
        "        hidden_size=1024,\n",
        "        depth=2,\n",
        "        learning_rate=1e-3,\n",
        "    ):\n",
        "        net_arch = dict(\n",
        "            pi=[hidden_size] * depth,\n",
        "            vf=[64]\n",
        "        )\n",
        "        super().__init__(\n",
        "            observation_space=observation_space,\n",
        "            action_space=action_space,\n",
        "            lr_schedule=lambda _: learning_rate,\n",
        "            net_arch=net_arch,\n",
        "            activation_fn=nn.ReLU,\n",
        "            features_extractor_class=FlattenExtractor,\n",
        "            optimizer_class=torch.optim.Adam,\n",
        "        )\n",
        "\n",
        "    def _build(self, lr_schedule):\n",
        "        self.features_extractor = self.features_extractor_class(self.observation_space)\n",
        "        self.features_dim = self.features_extractor.features_dim\n",
        "\n",
        "        self.mlp_extractor = MlpExtractor(\n",
        "            self.features_dim,\n",
        "            net_arch=self.net_arch,\n",
        "            activation_fn=self.activation_fn,\n",
        "        )\n",
        "\n",
        "        self.value_net = nn.Linear(self.mlp_extractor.latent_dim_vf, 1)\n",
        "\n",
        "        latent_dim_pi = self.mlp_extractor.latent_dim_pi\n",
        "        self.action_net, self.log_std = self.action_dist.proba_distribution_net(\n",
        "            latent_dim=latent_dim_pi,\n",
        "            log_std_init=self.log_std_init\n",
        "        )\n",
        "\n",
        "\n",
        "# Load the UnconditionalPolicy model\n",
        "def load_model(model_class, model_path, observation_space, action_space):\n",
        "    model = model_class(\n",
        "        observation_space=observation_space,\n",
        "        action_space=action_space,\n",
        "        hidden_size=1024,\n",
        "        depth=2\n",
        "    )\n",
        "    model.load_state_dict(torch.load(model_path, map_location=torch.device('cuda')))\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "\n",
        "# Set the OpenGL backend for headless rendering\n",
        "os.environ[\"MUJOCO_GL\"] = \"egl\"\n",
        "\n",
        "\n",
        "# Function to save frames to video\n",
        "def save_video_from_frames(frames, video_filename):\n",
        "    writer = imageio.get_writer(video_filename, fps=60)\n",
        "    for frame in frames:\n",
        "        writer.append_data(frame)\n",
        "    writer.close()\n",
        "    print(f\"Video saved at: {video_filename}\")\n",
        "\n",
        "\n",
        "# Evaluate the model and save video\n",
        "def evaluate_model_and_save_video(model, env_name, video_filename, state_mean, state_std, num_evaluations=10, desired_return=3600 * 0.001):\n",
        "    env = gym.make(env_name, render_mode=\"rgb_array\")\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    frames = []\n",
        "    total_rewards = []\n",
        "\n",
        "    for ep in range(num_evaluations):\n",
        "        obs, _ = env.reset()\n",
        "        total_reward = 0\n",
        "        done = False\n",
        "        desired_return_ep = desired_return  # Reset desired return for this episode\n",
        "\n",
        "        while not done:\n",
        "            # Normalize state\n",
        "            state = (torch.tensor(obs, dtype=torch.float32).to(device) - state_mean) / state_std\n",
        "            state = state.unsqueeze(0)\n",
        "\n",
        "            # Add desired return to state\n",
        "            desired_return_tensor = torch.tensor([[desired_return_ep]], dtype=torch.float32).to(device)\n",
        "            augmented_state = torch.cat([state, desired_return_tensor], dim=1)\n",
        "\n",
        "            # Predict action\n",
        "            action = model._predict(augmented_state, deterministic=True).detach().cpu().numpy().flatten()\n",
        "            action = np.clip(action, env.action_space.low, env.action_space.high)  # Clip actions\n",
        "\n",
        "            # Step environment\n",
        "            obs, reward, terminated, truncated, _ = env.step(action)\n",
        "            done = terminated or truncated\n",
        "            total_reward += reward\n",
        "\n",
        "            # Update desired return\n",
        "            desired_return_ep -= reward * 0.001\n",
        "            frame = env.render()\n",
        "            frames.append(frame)\n",
        "\n",
        "        print(f\"Sum of Reward for this episode: {total_reward}\")\n",
        "        total_rewards.append(total_reward)\n",
        "\n",
        "    save_video_from_frames(frames, video_filename)\n",
        "    avg_reward = np.mean(total_rewards)\n",
        "    print(f\"Average Reward over {num_evaluations} evaluations: {avg_reward}\")\n",
        "    return avg_reward\n",
        "\n",
        "\n",
        "# Main function\n",
        "def main():\n",
        "    dataset_name = \"hopper-medium-expert-v2\"\n",
        "    model_path = f\"trained_mle_model_{dataset_name}.pth\"\n",
        "    video_filename = f\"./{dataset_name}_evaluation.mp4\"\n",
        "\n",
        "    env_name = dataset_name.split('-')[0].replace('hopper', 'Hopper') + '-v4'\n",
        "    env = gym.make(env_name, render_mode=\"rgb_array\")\n",
        "\n",
        "    action_space = env.action_space\n",
        "    augmented_obs_space = gym.spaces.Box(\n",
        "        low=np.concatenate([env.observation_space.low, [-np.inf]]),\n",
        "        high=np.concatenate([env.observation_space.high, [np.inf]]),\n",
        "        dtype=np.float32\n",
        "    )\n",
        "\n",
        "    # Load the model\n",
        "    model = load_model(UnconditionalPolicy, model_path, augmented_obs_space, action_space)\n",
        "\n",
        "    # Load dataset statistics for normalization\n",
        "    dataset = d4rl_offline_dataset(dataset_name)\n",
        "    states = dataset['observations']\n",
        "    state_mean = torch.tensor(states.mean(axis=0), dtype=torch.float32).to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    state_std = torch.tensor(states.std(axis=0) + 1e-6, dtype=torch.float32).to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # Evaluate the model and save video\n",
        "    avg_reward = evaluate_model_and_save_video(\n",
        "        model,\n",
        "        env_name,\n",
        "        video_filename,\n",
        "        state_mean,\n",
        "        state_std,\n",
        "        num_evaluations=10,\n",
        "        desired_return=3600 * 0.001\n",
        "    )\n",
        "\n",
        "    print(f\"Final Average Reward for {dataset_name}: {avg_reward}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xh8JFeritus3",
        "outputId": "23577189-fafe-4766-a9da-3cd7bc654a42"
      },
      "execution_count": 19,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gymnasium/envs/registration.py:517: DeprecationWarning: \u001b[33mWARN: The environment Hopper-v4 is out of date. You should consider upgrading to version `v5`.\u001b[0m\n",
            "  logger.deprecation(\n",
            "<ipython-input-19-f5eaa4d3a4ae>:63: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path, map_location=torch.device('cuda')))\n",
            "load datafile: 100%|██████████| 9/9 [00:03<00:00,  2.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded and saved at: /root/.d4rl/datasets/hopper_medium_expert-v2.hdf5\n",
            "Sum of Reward for this episode: 3384.514099871218\n",
            "Sum of Reward for this episode: 2494.3416450073314\n",
            "Sum of Reward for this episode: 2579.4993052006303\n",
            "Sum of Reward for this episode: 3566.669651624607\n",
            "Sum of Reward for this episode: 3632.1642348205987\n",
            "Sum of Reward for this episode: 3368.264849530412\n",
            "Sum of Reward for this episode: 1574.8869895142625\n",
            "Sum of Reward for this episode: 3567.374677517645\n",
            "Sum of Reward for this episode: 3592.376119709841\n",
            "Sum of Reward for this episode: 3508.5736931077454\n",
            "Video saved at: ./hopper-medium-expert-v2_evaluation.mp4\n",
            "Average Reward over 10 evaluations: 3126.866526590429\n",
            "Final Average Reward for hopper-medium-expert-v2: 3126.866526590429\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "import torch\n",
        "import numpy as np\n",
        "import os\n",
        "import imageio\n",
        "from stable_baselines3.common import policies\n",
        "from just_d4rl import d4rl_offline_dataset\n",
        "from stable_baselines3.common.torch_layers import FlattenExtractor, MlpExtractor\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "# Define UnconditionalPolicy\n",
        "class UnconditionalPolicy(policies.ActorCriticPolicy):\n",
        "    def __init__(\n",
        "        self,\n",
        "        observation_space,\n",
        "        action_space,\n",
        "        hidden_size=1024,\n",
        "        depth=2,\n",
        "        learning_rate=1e-3,\n",
        "    ):\n",
        "        net_arch = dict(\n",
        "            pi=[hidden_size] * depth,\n",
        "            vf=[64]\n",
        "        )\n",
        "        super().__init__(\n",
        "            observation_space=observation_space,\n",
        "            action_space=action_space,\n",
        "            lr_schedule=lambda _: learning_rate,\n",
        "            net_arch=net_arch,\n",
        "            activation_fn=nn.ReLU,\n",
        "            features_extractor_class=FlattenExtractor,\n",
        "            optimizer_class=torch.optim.Adam,\n",
        "        )\n",
        "\n",
        "    def _build(self, lr_schedule):\n",
        "        self.features_extractor = self.features_extractor_class(self.observation_space)\n",
        "        self.features_dim = self.features_extractor.features_dim\n",
        "\n",
        "        self.mlp_extractor = MlpExtractor(\n",
        "            self.features_dim,\n",
        "            net_arch=self.net_arch,\n",
        "            activation_fn=self.activation_fn,\n",
        "        )\n",
        "\n",
        "        self.value_net = nn.Linear(self.mlp_extractor.latent_dim_vf, 1)\n",
        "\n",
        "        latent_dim_pi = self.mlp_extractor.latent_dim_pi\n",
        "        self.action_net, self.log_std = self.action_dist.proba_distribution_net(\n",
        "            latent_dim=latent_dim_pi,\n",
        "            log_std_init=self.log_std_init\n",
        "        )\n",
        "\n",
        "\n",
        "# Load the UnconditionalPolicy model\n",
        "def load_model(model_class, model_path, observation_space, action_space):\n",
        "    model = model_class(\n",
        "        observation_space=observation_space,\n",
        "        action_space=action_space,\n",
        "        hidden_size=1024,\n",
        "        depth=2\n",
        "    )\n",
        "    model.load_state_dict(torch.load(model_path, map_location=torch.device('cuda')))\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "\n",
        "# Set the OpenGL backend for headless rendering\n",
        "os.environ[\"MUJOCO_GL\"] = \"egl\"\n",
        "\n",
        "\n",
        "# Function to save frames to video\n",
        "def save_video_from_frames(frames, video_filename):\n",
        "    writer = imageio.get_writer(video_filename, fps=60)\n",
        "    for frame in frames:\n",
        "        writer.append_data(frame)\n",
        "    writer.close()\n",
        "    print(f\"Video saved at: {video_filename}\")\n",
        "\n",
        "\n",
        "# Evaluate the model and save video\n",
        "def evaluate_model_and_save_video(model, env_name, video_filename, state_mean, state_std, num_evaluations=10, desired_return=5000 * 0.001):\n",
        "    env = gym.make(env_name, render_mode=\"rgb_array\")\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    frames = []\n",
        "    total_rewards = []\n",
        "\n",
        "    for ep in range(num_evaluations):\n",
        "        obs, _ = env.reset()\n",
        "        total_reward = 0\n",
        "        done = False\n",
        "        desired_return_ep = desired_return  # Reset desired return for this episode\n",
        "\n",
        "        while not done:\n",
        "            # Normalize state\n",
        "            state = (torch.tensor(obs, dtype=torch.float32).to(device) - state_mean) / state_std\n",
        "            state = state.unsqueeze(0)\n",
        "\n",
        "            # Add desired return to state\n",
        "            desired_return_tensor = torch.tensor([[desired_return_ep]], dtype=torch.float32).to(device)\n",
        "            augmented_state = torch.cat([state, desired_return_tensor], dim=1)\n",
        "\n",
        "            # Predict action\n",
        "            action = model._predict(augmented_state, deterministic=True).detach().cpu().numpy().flatten()\n",
        "            action = np.clip(action, env.action_space.low, env.action_space.high)  # Clip actions\n",
        "\n",
        "            # Step environment\n",
        "            obs, reward, terminated, truncated, _ = env.step(action)\n",
        "            done = terminated or truncated\n",
        "            total_reward += reward\n",
        "\n",
        "            # Update desired return\n",
        "            desired_return_ep -= reward * 0.001\n",
        "            frame = env.render()\n",
        "            frames.append(frame)\n",
        "\n",
        "        print(f\"Sum of Reward for this episode: {total_reward}\")\n",
        "        total_rewards.append(total_reward)\n",
        "\n",
        "    save_video_from_frames(frames, video_filename)\n",
        "    avg_reward = np.mean(total_rewards)\n",
        "    print(f\"Average Reward over {num_evaluations} evaluations: {avg_reward}\")\n",
        "    return avg_reward\n",
        "\n",
        "\n",
        "# Main function\n",
        "def main():\n",
        "    dataset_name = \"walker2d-medium-expert-v2\"\n",
        "    model_path = f\"trained_mle_model_{dataset_name}.pth\"\n",
        "    video_filename = f\"./{dataset_name}_evaluation.mp4\"\n",
        "\n",
        "    env_name = dataset_name.split('-')[0].replace('walker2d', 'Walker2d') + '-v4'\n",
        "    env = gym.make(env_name, render_mode=\"rgb_array\")\n",
        "\n",
        "    action_space = env.action_space\n",
        "    augmented_obs_space = gym.spaces.Box(\n",
        "        low=np.concatenate([env.observation_space.low, [-np.inf]]),\n",
        "        high=np.concatenate([env.observation_space.high, [np.inf]]),\n",
        "        dtype=np.float32\n",
        "    )\n",
        "\n",
        "    # Load the model\n",
        "    model = load_model(UnconditionalPolicy, model_path, augmented_obs_space, action_space)\n",
        "\n",
        "    # Load dataset statistics for normalization\n",
        "    dataset = d4rl_offline_dataset(dataset_name)\n",
        "    states = dataset['observations']\n",
        "    state_mean = torch.tensor(states.mean(axis=0), dtype=torch.float32).to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    state_std = torch.tensor(states.std(axis=0) + 1e-6, dtype=torch.float32).to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # Evaluate the model and save video\n",
        "    avg_reward = evaluate_model_and_save_video(\n",
        "        model,\n",
        "        env_name,\n",
        "        video_filename,\n",
        "        state_mean,\n",
        "        state_std,\n",
        "        num_evaluations=10,\n",
        "        desired_return=5000 * 0.001\n",
        "    )\n",
        "\n",
        "    print(f\"Final Average Reward for {dataset_name}: {avg_reward}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrrmuc1W1jR8",
        "outputId": "f2a74f24-cc3f-4e8f-acca-e70e28510239"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-f4ba6405f2d9>:63: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path, map_location=torch.device('cuda')))\n",
            "load datafile: 100%|██████████| 9/9 [00:04<00:00,  1.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded and saved at: /root/.d4rl/datasets/walker2d_medium_expert-v2.hdf5\n",
            "Sum of Reward for this episode: 4904.8224526156\n",
            "Sum of Reward for this episode: 4870.28563317747\n",
            "Sum of Reward for this episode: 4868.763126591738\n",
            "Sum of Reward for this episode: 4888.087381968669\n",
            "Sum of Reward for this episode: 4883.4723337021205\n",
            "Sum of Reward for this episode: 4905.227923898287\n",
            "Sum of Reward for this episode: 4908.204982869992\n",
            "Sum of Reward for this episode: 4899.835439343304\n",
            "Sum of Reward for this episode: 4883.56162887681\n",
            "Sum of Reward for this episode: 4894.967023848706\n",
            "Video saved at: ./walker2d-medium-expert-v2_evaluation.mp4\n",
            "Average Reward over 10 evaluations: 4890.72279268927\n",
            "Final Average Reward for walker2d-medium-expert-v2: 4890.72279268927\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AKxYEHUr8-Fd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}