# R-D_project
Developing a Weighted Sampling Approach for Offline Reinforcement Learning Using Imbalanced RegressionÂ Techniques
Abstract
Offline reinforcement learning (RL) faces significant challenges when applied to imbalanced datasets. This
study proposes an improved methodology using advanced policy architectures, return-based augmentation,
and structured sampling techniques. Evaluations across environments, including HalfCheetah, Hopper, and
Walker2d, demonstrate substantial improvements in normalized scores and stability. The proposed approach
achieved returns of up to 106.45 with significantly reduced variance, validating its effectiveness in leveraging
offline datasets. These results suggest that integrating advanced architectures and state-action augmentation
techniques can generalize well across diverse environments, offering new insights into offline RL optimization.

Comparative Analysis
![image](https://github.com/user-attachments/assets/df3fca1e-ec63-4bb9-8efe-06ad4bf6faab)

Videos:

halfcheetah:
https://github.com/user-attachments/assets/b14ab4e8-e6e9-471f-af74-0781fa26da5a

hopper:

https://github.com/user-attachments/assets/fbc8e900-1aac-42d2-bb24-34a7006b9e6f

walker2d
https://github.com/user-attachments/assets/443e4ade-46a7-4883-9ebb-3adb1f9e5090


