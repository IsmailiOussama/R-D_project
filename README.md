# R-D_project 
Developing a Weighted Sampling Approach for Offline Reinforcement Learning Using Imbalanced RegressionÂ Techniques
# Abstract
Offline reinforcement learning (RL) faces significant challenges when applied to imbalanced datasets. This
study proposes an improved methodology using advanced policy architectures, return-based augmentation,
and structured sampling techniques. Evaluations across environments, including HalfCheetah, Hopper, and
Walker2d, demonstrate substantial improvements in normalized scores and stability. The proposed approach
achieved returns of up to 106.45 with significantly reduced variance, validating its effectiveness in leveraging
offline datasets. These results suggest that integrating advanced architectures and state-action augmentation
techniques can generalize well across diverse environments, offering new insights into offline RL optimization.

# Comparative Analysis
![image](https://github.com/user-attachments/assets/df3fca1e-ec63-4bb9-8efe-06ad4bf6faab)
# Article: https://drive.google.com/file/d/1GPQl6dW6-oU8y3Gm5UxwY6q4u-ck3bT7/view?usp=drivesdk
# Videos:

halfcheetah:



https://github.com/user-attachments/assets/febf4049-d13e-4898-94f7-e4edc6710975

hopper:


https://github.com/user-attachments/assets/7040dcfd-9abd-4b83-a670-dd9309d4750f

walker2d:



https://github.com/user-attachments/assets/1b514dbb-3e33-4a00-994e-2939ed9788c3

